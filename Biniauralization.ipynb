{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b69dfad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate:\n",
      "44100\n",
      "Sampling Rate:\n",
      "[44100.]\n",
      "Source Positions:\n",
      "[[  0. -40.   1.]\n",
      " [  6. -40.   1.]\n",
      " [ 13. -40.   1.]\n",
      " ...\n",
      " [300.  80.   1.]\n",
      " [330.  80.   1.]\n",
      " [  0.  90.   1.]]\n",
      "HRTF Left shape:\n",
      "(727040,)\n",
      "HRTF Right shape:\n",
      "(727040,)\n",
      "Stereo Signal Left Channel Shape: (344195,)\n",
      "Stereo Signal Right Channel Shape: (344195,)\n",
      "Convolved Left Channel Shape: (344195,)\n",
      "Convolved Right Channel Shape: (344195,)\n",
      "Binaural audio saved to Output/music_binaural_output.wav\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from scipy.signal import fftconvolve\n",
    "import pysofaconventions as sofa\n",
    "\n",
    "# Load stereo audio file\n",
    "input_file = 'Data/CTHS3_Acid_Bass_Loop_01_C_123.wav'  # Replace with your stereo file\n",
    "stereo_signal, sample_rate = sf.read(input_file)\n",
    "\n",
    "print(\"Sample rate:\")\n",
    "print(sample_rate)\n",
    "\n",
    "# Ensure the input is stereo\n",
    "if stereo_signal.ndim != 2 or stereo_signal.shape[1] != 2:\n",
    "    raise ValueError(\"Input file must be a stereo audio file.\")\n",
    "\n",
    "# Load HRTF data from a SOFA file\n",
    "sofa_file = 'Data/mit_kemar_normal_pinna.sofa'  # Replace with the path to your SOFA file\n",
    "hrtf = sofa.SOFAFile(sofa_file, mode='r') \n",
    "\n",
    "# # Print available attributes in the SOFA file\n",
    "# print(\"Attributes in the SOFA file:\")\n",
    "# print(hrtf.__dict__.keys())\n",
    "\n",
    "# # Access sampling rate\n",
    "print(\"Sampling Rate:\")\n",
    "print(hrtf.getSamplingRate())\n",
    "\n",
    "# Access source positions\n",
    "# print(hrtf.getSourcePositionValues())\n",
    "\n",
    "# # Access impulse response data\n",
    "# print(\"Impulse Responses:\")\n",
    "# print(hrtf.Data_IR)\n",
    "\n",
    "# Extract HRTF for a specific position (e.g., azimuth = 0°, elevation = 0°)\n",
    "# Find the index of the desired position\n",
    "source_positions = hrtf.getSourcePositionValues()\n",
    "print(\"Source Positions:\")\n",
    "print(np.round(source_positions))\n",
    "\n",
    "# print(\"source_positions[:, 0]\")\n",
    "# print(np.round(source_positions[:, 0]))\n",
    "\n",
    "# Find the index of the desired position\n",
    "azimuth = 0\n",
    "elevation = 0\n",
    "\n",
    "source_positions = np.round(source_positions, 2);\n",
    "\n",
    "position_index = np.where(\n",
    "    (source_positions[:, 0] == azimuth) & (source_positions[:, 1] == elevation)\n",
    ")[0][0]\n",
    "\n",
    "# Get the HRTF impulse responses for the left and right ears\n",
    "hrtf_left = hrtf.getDataIR().flatten()  # Ensure 1D\n",
    "hrtf_right = hrtf.getDataIR().flatten()  # Ensure 1D\n",
    "\n",
    "# Check the shape of the HRTF data\n",
    "print(\"HRTF Left shape:\")\n",
    "print(hrtf_left.shape)\n",
    "print(\"HRTF Right shape:\")\n",
    "print(hrtf_right.shape)\n",
    "# Ensure the HRTF data is 1D\n",
    "if hrtf_left.ndim > 1:\n",
    "    hrtf_left = hrtf_left[:, position_index]\n",
    "if hrtf_right.ndim > 1:\n",
    "    hrtf_right = hrtf_right[:, position_index]\n",
    "\n",
    "print(\"Stereo Signal Left Channel Shape:\", stereo_signal[:, 0].shape)\n",
    "print(\"Stereo Signal Right Channel Shape:\", stereo_signal[:, 1].shape)\n",
    "print(\"Convolved Left Channel Shape:\", left_channel.shape)\n",
    "print(\"Convolved Right Channel Shape:\", right_channel.shape)\n",
    "\n",
    "# Apply HRTF filters to each channel\n",
    "left_channel = fftconvolve(stereo_signal[:, 0], hrtf_left, mode='same')\n",
    "right_channel = fftconvolve(stereo_signal[:, 1], hrtf_right, mode='same')\n",
    "\n",
    "# Combine the processed channels into a binaural signal\n",
    "binaural_signal = np.column_stack((left_channel, right_channel))\n",
    "\n",
    "# Save the binaural audio to a new file\n",
    "output_file = 'Output/music_binaural_output.wav'\n",
    "sf.write(output_file, binaural_signal, sample_rate)\n",
    "\n",
    "print(f\"Binaural audio saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d610acf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of stereo_signal[:, 0]: (344195,)\n",
      "Shape of hrtf_left: (2304, 2, 256)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of stereo_signal[:, 0]:\", stereo_signal[:, 0].shape)\n",
    "print(\"Shape of hrtf_left:\", hrtf_left.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9979c19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRIR Left Shape: (1179648,)\n",
      "HRIR Right Shape: (1179648,)\n",
      "HRIR Left Data: [-0.00216339 -0.00218606 -0.00575749 ... -0.00364431 -0.00466137\n",
      " -0.00475264]\n",
      "HRIR Right Data: [-0.00216339 -0.00218606 -0.00575749 ... -0.00364431 -0.00466137\n",
      " -0.00475264]\n"
     ]
    }
   ],
   "source": [
    "print(\"HRIR Left Shape:\", hrtf_left.shape)\n",
    "print(\"HRIR Right Shape:\", hrtf_right.shape)\n",
    "print(\"HRIR Left Data:\", hrtf_left)\n",
    "print(\"HRIR Right Data:\", hrtf_right)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
